{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rebecadieb/ev-telemetry-simulator-spark-pipeline-colab-kafka-mongo/blob/main/EV_Telemetry_Simulator_%26_Spark_Pipeline_(Colab_Kafka_Mongo).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Simulador de Telemetria de Frota de Carros El√©tricos**\n",
        "\n",
        "O c√≥digo abaixo gera sinais (telemetria) de uma frota de ve√≠culos el√©tricos, permitindo testes e prototipa√ß√£o de pipelines de ingest√£o e an√°lise de dados de telemetria.\n",
        "\n",
        "Os dados gerados simulam condi√ß√µes quase realistas de ve√≠culos em movimento ou em carga.\n",
        "\n",
        "---\n",
        "\n",
        "## **Objetivos**\n",
        "\n",
        "- Criar dados sint√©ticos de telemetria EV para testes de pipelines e modelos.\n",
        "- Suportar m√∫ltiplos modos de sa√≠da: `stdout`, `arquivo JSON`, `HTTP POST`, `Kafka`.\n",
        "- Permitir controle de par√¢metros (n¬∫ de ve√≠culos, frequ√™ncia, dura√ß√£o, semente aleat√≥ria).\n",
        "- Gerar informa√ß√µes de mec√¢nica, energia, localiza√ß√£o e eventos de falha.\n",
        "\n",
        "---\n",
        "\n",
        "## **Estrutura do Output**\n",
        "\n",
        "Cada registro √© um JSON no seguinte formato:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"schema_version\": \"1.0.0\",\n",
        "  \"vehicle_id\": \"EV-00001\",\n",
        "  \"timestamp\": \"2025-08-24T18:05:30.123456+00:00\",\n",
        "  \"metrics\": {\n",
        "    \"soc_pct\": 85.3,\n",
        "    \"pack_voltage_v\": 380.5,\n",
        "    \"pack_current_a\": -42.7,\n",
        "    \"power_kw\": 16.4,\n",
        "    \"battery_temp_c\": 29.1,\n",
        "    \"motor_temp_c\": 47.2,\n",
        "    \"coolant_temp_c\": 32.0,\n",
        "    \"tyre_pressure_kpa\": [225.1, 224.7, 223.5, 226.3],\n",
        "    \"speed_kph\": 72.4,\n",
        "    \"odometer_km\": 50321.8,\n",
        "    \"latitude\": -23.5505,\n",
        "    \"longitude\": -46.6333,\n",
        "    \"heading_deg\": 145.3,\n",
        "    \"ambient_temp_c\": 27.5,\n",
        "    \"is_charging\": false,\n",
        "    \"charge_power_kw\": 0.0,\n",
        "    \"health_score\": 0.95\n",
        "  },\n",
        "  \"events\": {\n",
        "    \"fault_code\": null\n",
        "  }\n",
        "}\n"
      ],
      "metadata": {
        "id": "ITvgA4-U_iO5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìñ Dicion√°rio de Dados ‚Äì Simulador de Telemetria EV\n",
        "\n",
        "Cada linha gerada pelo simulador corresponde a um evento de telemetria de um ve√≠culo el√©trico (EV).  \n",
        "O formato de sa√≠da √© **JSON** (pode ser convertido para CSV/Parquet).\n",
        "\n",
        "## Raiz\n",
        "\n",
        "| Campo             | Tipo      | Obrigat√≥rio | Formato / Unidade         | Descri√ß√£o |\n",
        "|-------------------|-----------|-------------|---------------------------|-----------|\n",
        "| **schema_version** | string   | Sim         | Texto (ex.: `\"1.0.0\"`)    | Vers√£o do schema da mensagem para garantir compatibilidade futura. |\n",
        "| **vehicle_id**     | string   | Sim         | `EV-` + 5 d√≠gitos | Identificador √∫nico do ve√≠culo na frota. |\n",
        "| **timestamp**      | datetime | Sim         | ISO 8601 UTC (`YYYY-MM-DDThh:mm:ss.ssssss+00:00`) | Momento exato de gera√ß√£o do evento de telemetria. |\n",
        "| **metrics**        | objeto   | Sim         | Estrutura JSON aninhada   | Grupo de m√©tricas cont√≠nuas (sinais vitais e sensores do ve√≠culo). |\n",
        "| **events**         | objeto   | Sim         | Estrutura JSON aninhada   | Grupo de eventos discretos (falhas e alertas do ve√≠culo). |\n",
        "\n",
        "\n",
        "## Metrics + Events\n",
        "\n",
        "| Campo              | Tipo           | Unidade / Formato      | Obrigat√≥rio | Dom√≠nio / Valores v√°lidos | Descri√ß√£o |\n",
        "|--------------------|----------------|------------------------|-------------|---------------------------|-----------|\n",
        "| **soc_pct**        | float          | %                      | Sim         | 0 ‚Äì 100                   | State of Charge: n√≠vel de carga da bateria. |\n",
        "| **pack_voltage_v** | float          | Volts (V)              | Sim         | 200 ‚Äì 900                 | Tens√£o do pack de baterias. |\n",
        "| **pack_current_a** | float          | Amperes (A)            | Sim         | -2000 ‚Äì 2000              | Corrente el√©trica do pack (negativa em carga, positiva em descarga). |\n",
        "| **power_kw**       | float          | Quilowatts (kW)        | Sim         | -300 ‚Äì 300                | Pot√™ncia instant√¢nea consumida ou fornecida. |\n",
        "| **battery_temp_c** | float          | Graus Celsius (¬∞C)     | Sim         | -30 ‚Äì 90                  | Temperatura m√©dia do pack de baterias. |\n",
        "| **motor_temp_c**   | float          | Graus Celsius (¬∞C)     | Sim         | -30 ‚Äì 150                 | Temperatura do motor el√©trico. |\n",
        "| **coolant_temp_c** | float          | Graus Celsius (¬∞C)     | Sim         | -30 ‚Äì 120                 | Temperatura do fluido de arrefecimento. |\n",
        "| **tyre_pressure_kpa** | array[float] | Quilopascal (kPa)      | Sim         | 120 ‚Äì 260                 | Press√£o dos quatro pneus (ordem: dianteiro-esq., dianteiro-dir., traseiro-esq., traseiro-dir.). |\n",
        "| **speed_kph**      | float          | km/h                   | Sim         | 0 ‚Äì 250                   | Velocidade atual do ve√≠culo. |\n",
        "| **odometer_km**    | float          | km                     | Sim         | 0 ‚Äì 2.000.000             | Quilometragem acumulada do ve√≠culo (od√¥metro). |\n",
        "| **latitude**       | float          | graus decimais         | Sim         | -90 ‚Äì 90                  | Latitude aproximada (GPS). |\n",
        "| **longitude**      | float          | graus decimais         | Sim         | -180 ‚Äì 180                | Longitude aproximada (GPS). |\n",
        "| **heading_deg**    | float          | graus (0‚Äì360)          | Sim         | 0 ‚Äì 360                   | Dire√ß√£o/rumo de movimento em rela√ß√£o ao norte. |\n",
        "| **ambient_temp_c** | float          | Graus Celsius (¬∞C)     | Sim         | -50 ‚Äì 80                  | Temperatura ambiente externa. |\n",
        "| **is_charging**    | boolean        | true / false           | Sim         | `true` ou `false`         | Indica se o ve√≠culo est√° em processo de recarga. |\n",
        "| **charge_power_kw**| float          | Quilowatts (kW)        | Sim         | 0 ‚Äì 400                   | Pot√™ncia de carga aplicada (0 se n√£o estiver carregando). |\n",
        "| **health_score**   | float          | Escala 0‚Äì1             | Sim         | 0 ‚Äì 1                     | √çndice de sa√∫de da bateria (1=√≥tima, 0.5=degradada). |\n",
        "| **fault_code**     | string / null  | Texto ou `null`        | N√£o         | `null` (sem falha) ou:<br>‚Ä¢ `BMS_WARN_TEMP`<br>‚Ä¢ `TIRE_PRESS_LOW`<br>‚Ä¢ `COOLANT_LEVEL_LOW`<br>‚Ä¢ `BRAKE_PAD_WEAR` | C√≥digo de falha ativa do ve√≠culo (eventos discretos). |"
      ],
      "metadata": {
        "id": "vpK9QlF1Z0AV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instala√ß√£o e checagem do MongoDB"
      ],
      "metadata": {
        "id": "0kgUpDgpO0K1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# libs Python\n",
        "!pip -q install pymongo\n",
        "\n",
        "# pastas\n",
        "!mkdir -p /content/mongodb/data /content/mongodb/log"
      ],
      "metadata": {
        "id": "JJ3_OethMS4j"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "set -euo pipefail\n",
        "mkdir -p /content/mongodb/data /content/mongodb/log\n",
        "\n",
        "urls=(\n",
        "  \"https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-ubuntu2204-7.0.14.tgz\"\n",
        "  \"https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-ubuntu2204-7.0.13.tgz\"\n",
        "  \"https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-ubuntu2204-7.0.12.tgz\"\n",
        "  \"https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-ubuntu2204-6.0.18.tgz\"\n",
        "  \"https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-ubuntu2004-6.0.18.tgz\"\n",
        ")\n",
        "ok=\"\"\n",
        "for u in \"${urls[@]}\"; do\n",
        "  echo \">> tentando $u\"\n",
        "  if wget -q \"$u\" -O /content/mongodb.tgz; then\n",
        "    tar -xzf /content/mongodb.tgz -C /content/\n",
        "    ok=\"$(find /content -maxdepth 1 -type d -name 'mongodb-linux-*' | head -n1)\"\n",
        "    break\n",
        "  fi\n",
        "done\n",
        "if [ -z \"$ok\" ]; then\n",
        "  echo \"Falhei em baixar bin√°rio do MongoDB.\" >&2; exit 1\n",
        "fi\n",
        "\n",
        "ln -sfn \"$ok/bin/mongod\" /content/mongodb/mongod\n",
        "ln -sfn \"$ok/bin/mongo\"  /content/mongodb/mongo\n",
        "\n",
        "nohup /content/mongodb/mongod \\\n",
        "  --dbpath /content/mongodb/data \\\n",
        "  --bind_ip 127.0.0.1 --port 27017 \\\n",
        "  --logpath /content/mongodb/log/mongod.log \\\n",
        "  --wiredTigerCacheSizeGB 0.25 >/dev/null 2>&1 &\n",
        "\n",
        "sleep 2\n",
        "pgrep -a mongod || { echo \"mongod N√ÉO est√° rodando\"; tail -n 50 /content/mongodb/log/mongod.log; exit 1; }\n",
        "echo \"‚úÖ mongod ativo em 127.0.0.1:27017\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNyult3tOEGi",
        "outputId": "7dbd91b4-b66b-418c-affe-a7120095dcf6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> tentando https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-ubuntu2204-7.0.14.tgz\n",
            "19448 /content/mongodb/mongod --dbpath /content/mongodb/data --bind_ip 127.0.0.1 --port 27017 --logpath /content/mongodb/log/mongod.log --wiredTigerCacheSizeGB 0.25\n",
            "‚úÖ mongod ativo em 127.0.0.1:27017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pymongo import MongoClient\n",
        "cli = MongoClient(\"mongodb://127.0.0.1:27017\", serverSelectionTimeoutMS=3000)\n",
        "cli.admin.command(\"ping\")\n",
        "cli.close()\n",
        "print(\"‚úÖ Mongo OK no 127.0.0.1:27017\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fE5255IEOLHf",
        "outputId": "304c53a9-8d20-42c4-c767-37a7dd79d7cc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Mongo OK no 127.0.0.1:27017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install confluent-kafka"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEo213LUOw7U",
        "outputId": "4fbbf4ba-29c7-49ef-f240-6ea6ad0fb893"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: confluent-kafka in /usr/local/lib/python3.12/dist-packages (2.11.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classe para simula√ß√£o"
      ],
      "metadata": {
        "id": "YL2nObtaZ8Nk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from pymongo import MongoClient\n",
        "    _HAS_PYMONGO = True\n",
        "except Exception:\n",
        "    _HAS_PYMONGO = False\n",
        "\n",
        "class MongoAlertStore:\n",
        "    def __init__(self, uri: str = \"mongodb://127.0.0.1:27017\",\n",
        "                 db: str = \"telemetria\",\n",
        "                 collection: str = \"ev_alerts\",\n",
        "                 ttl_days: int | None = 30):\n",
        "        if not _HAS_PYMONGO:\n",
        "            raise RuntimeError(\"pymongo n√£o est√° instalado. Rode: !pip install pymongo\")\n",
        "        # conecta e valida\n",
        "        self.client = MongoClient(uri, serverSelectionTimeoutMS=5000)\n",
        "        self.client.admin.command(\"ping\")\n",
        "        self.col = self.client[db][collection]\n",
        "        # √≠ndices √∫teis\n",
        "        self.col.create_index([(\"vehicle_id\", 1), (\"ts_dt\", -1)])\n",
        "        if ttl_days is not None and ttl_days > 0:\n",
        "            # TTL precisa de datetime 'naive' (UTC) num campo\n",
        "            self.col.create_index(\"ts_dt\", expireAfterSeconds=int(ttl_days * 86400))\n",
        "\n",
        "    def send(self, rec: dict):\n",
        "        m = rec[\"metrics\"]; e = rec.get(\"events\") or {}\n",
        "        tsdt = datetime.fromisoformat(rec[\"timestamp\"])\n",
        "        # normaliza pra 'naive' UTC (compat√≠vel com TTL)\n",
        "        if tsdt.tzinfo:\n",
        "            tsdt = tsdt.astimezone(timezone.utc).replace(tzinfo=None)\n",
        "        doc = {\n",
        "            \"ts\": rec[\"timestamp\"],\n",
        "            \"ts_dt\": tsdt,\n",
        "            \"vehicle_id\": rec[\"vehicle_id\"],\n",
        "            \"soc_pct\": m[\"soc_pct\"],\n",
        "            \"power_kw\": m[\"power_kw\"],\n",
        "            \"latitude\": m[\"latitude\"],\n",
        "            \"longitude\": m[\"longitude\"],\n",
        "            \"fault_code\": e.get(\"fault_code\"),\n",
        "            \"payload\": rec,  # guarda evento completo pra reprocesso\n",
        "        }\n",
        "        self.col.insert_one(doc)\n",
        "\n",
        "    def close(self):\n",
        "        try:\n",
        "            self.client.close()\n",
        "        except:\n",
        "            pass"
      ],
      "metadata": {
        "id": "wW0K5wZVMa1t"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulador de Frota de Carros El√©tricos\n",
        "# Sa√≠das: stdout | file(.jsonl) | http | kafka\n",
        "\n",
        "import json, math, random, time, os, sys, re\n",
        "\n",
        "from datetime import datetime, timezone\n",
        "from urllib.parse import urlparse\n",
        "from urllib.request import Request, urlopen\n",
        "from urllib.error import URLError, HTTPError\n",
        "from google.colab import files\n",
        "from typing import Dict, List, Tuple\n",
        "from datetime import datetime, timezone\n",
        "from pyspark.sql import SparkSession, DataFrame\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "\n",
        "SCHEMA_VERSION = \"1.0.0\"\n",
        "\n",
        "def _sample_soc_biased(r):\n",
        "    # 97% perto de 100, 3% bem baixos\n",
        "    if r.random() < 0.03:\n",
        "        x = r.betavariate(1.5, 8.0)   # puxa para 0\n",
        "    else:\n",
        "        x = r.betavariate(7.0, 2.0)   # puxa para 1\n",
        "    return clamp(100.0*x, 0.0, 100.0)\n",
        "\n",
        "def iso_now():\n",
        "    return datetime.now(timezone.utc).isoformat()\n",
        "\n",
        "def clamp(v, lo, hi):\n",
        "    return max(lo, min(hi, v))\n",
        "\n",
        "class EV:\n",
        "    def __init__(self, vid, base_lat=-23.5505, base_lon=-46.6333, seed=None):\n",
        "        r = random.Random(seed if seed is not None else random.randrange(1<<30))\n",
        "        self.r = r\n",
        "        self.vehicle_id = f\"EV-{vid:05d}\"\n",
        "        self.soc = _sample_soc_biased(r)\n",
        "        self.pack_capacity_kwh = r.uniform(55, 90)    # kWh\n",
        "        self.voltage_nominal = r.uniform(320, 400)    # V\n",
        "        self.battery_temp = r.uniform(18, 30)         # ¬∞C\n",
        "        self.motor_temp = r.uniform(20, 35)           # ¬∞C\n",
        "        self.coolant_temp = r.uniform(18, 28)         # ¬∞C\n",
        "        self.tyre_pressure_kpa = [r.uniform(210, 240) for _ in range(4)]\n",
        "        self.speed_kph = r.uniform(0, 30)\n",
        "        self.heading_deg = r.uniform(0, 360)\n",
        "        self.lat = base_lat + r.uniform(-0.15, 0.15)\n",
        "        self.lon = base_lon + r.uniform(-0.15, 0.15)\n",
        "        self.odometer_km = r.uniform(10_000, 90_000)\n",
        "        self.is_charging = False\n",
        "        self.charge_power_kw = 0.0\n",
        "        self.health_score = r.uniform(0.92, 0.99)\n",
        "        self.aux_load_kw = r.uniform(0.3, 1.5)\n",
        "        self.ambient_temp = r.uniform(18, 34)\n",
        "        self.fault = None\n",
        "\n",
        "    def _earth_move(self, dt_s):\n",
        "        dist_km = (self.speed_kph * dt_s) / 3600.0\n",
        "        heading_rad = math.radians(self.heading_deg)\n",
        "        dlat = (dist_km * math.cos(heading_rad)) / 111.0\n",
        "        dlon = (dist_km * math.sin(heading_rad)) / (111.0 * max(0.1, math.cos(math.radians(self.lat))))\n",
        "        self.lat += dlat\n",
        "        self.lon += dlon\n",
        "        self.odometer_km += max(0.0, dist_km)\n",
        "\n",
        "    def _update_dynamics(self, dt_s):\n",
        "        r = self.r\n",
        "        # velocidade / dire√ß√£o\n",
        "        self.speed_kph = clamp(self.speed_kph + r.uniform(-1.5, 1.5) * dt_s, 0, 130)\n",
        "        self.heading_deg = (self.heading_deg + r.uniform(-4, 4) * (self.speed_kph/130.0)) % 360\n",
        "        # ambiente\n",
        "        self.ambient_temp = clamp(self.ambient_temp + r.uniform(-0.02, 0.02) * dt_s, 10, 42)\n",
        "\n",
        "        # pot√™ncia (simples e consistente)\n",
        "        v = self.speed_kph\n",
        "        aero_kw = 0.00015 * (v ** 3)\n",
        "        rolling_kw = 0.01 * v\n",
        "        temp_penalty = 0.15 if (self.ambient_temp < 12 or self.ambient_temp > 35) else 0.0\n",
        "        total_kw = aero_kw + rolling_kw + self.aux_load_kw + temp_penalty\n",
        "\n",
        "        # carga ocasional\n",
        "        if not self.is_charging and (self.soc < 20) and (r.random() < 0.03):\n",
        "            self.is_charging = True\n",
        "            self.charge_power_kw = r.uniform(30, 120)\n",
        "            self.speed_kph = 0.0\n",
        "\n",
        "        if self.is_charging:\n",
        "            charged_kwh = (self.charge_power_kw * dt_s) / 3600.0\n",
        "            self.soc = clamp(self.soc + (100 * charged_kwh / self.pack_capacity_kwh), 0, 100)\n",
        "            self.battery_temp = clamp(self.battery_temp + r.uniform(0.02, 0.08) * dt_s, -10, 60)\n",
        "            self.coolant_temp = clamp(self.coolant_temp + r.uniform(0.01, 0.05) * dt_s, -10, 55)\n",
        "            if self.soc >= 80 or r.random() < 0.005:\n",
        "                self.is_charging = False\n",
        "                self.charge_power_kw = 0.0\n",
        "        else:\n",
        "            used_kwh = (total_kw * dt_s) / 3600.0\n",
        "            self.soc = clamp(self.soc - (100 * used_kwh / self.pack_capacity_kwh), 0, 100)\n",
        "            heat_gain = 0.0008 * (v ** 2) + (total_kw * 0.015)\n",
        "            self.motor_temp = clamp(self.motor_temp + (heat_gain - 0.03) * dt_s, -10, 140)\n",
        "            self.battery_temp = clamp(self.battery_temp + (0.5 * heat_gain - 0.02) * dt_s, -10, 70)\n",
        "            self.coolant_temp = clamp(self.coolant_temp + (0.3 * heat_gain - 0.025) * dt_s, -10, 60)\n",
        "\n",
        "        # pneus + falhas leves\n",
        "        idx = r.randrange(4)\n",
        "        self.tyre_pressure_kpa[idx] = clamp(self.tyre_pressure_kpa[idx] + r.uniform(-0.5, 0.5), 170, 260)\n",
        "        if r.random() < 1e-4:\n",
        "            leak = r.randrange(4)\n",
        "            self.tyre_pressure_kpa[leak] = clamp(self.tyre_pressure_kpa[leak] - r.uniform(5, 15), 120, 260)\n",
        "\n",
        "        if self.fault is None and r.random() < 5e-4:\n",
        "            self.fault = r.choice([\"BMS_WARN_TEMP\",\"TIRE_PRESS_LOW\",\"COOLANT_LEVEL_LOW\",\"BRAKE_PAD_WEAR\"])\n",
        "        elif self.fault and r.random() < 1e-3:\n",
        "            self.fault = None\n",
        "\n",
        "        self._earth_move(dt_s)\n",
        "\n",
        "    def _electrics(self):\n",
        "        v = clamp(self.voltage_nominal + (self.soc - 50) * 0.5 + random.uniform(-2, 2), 280, 420)\n",
        "        if self.is_charging:\n",
        "            power_kw = self.charge_power_kw\n",
        "            current_a = (power_kw * 1000) / max(1.0, v)\n",
        "        else:\n",
        "            speed = self.speed_kph\n",
        "            aero_kw = 0.00015 * (speed ** 3)\n",
        "            rolling_kw = 0.01 * speed\n",
        "            temp_penalty = 0.15 if (self.ambient_temp < 12 or self.ambient_temp > 35) else 0.0\n",
        "            power_kw = aero_kw + rolling_kw + self.aux_load_kw + temp_penalty\n",
        "            current_a = (power_kw * 1000) / max(1.0, v)\n",
        "            current_a *= 1.05\n",
        "        return v, current_a, power_kw\n",
        "\n",
        "    def step(self, dt_s):\n",
        "        self._update_dynamics(dt_s)\n",
        "        pack_v, pack_a, power_kw = self._electrics()\n",
        "        penalty = 0.0\n",
        "        if self.battery_temp > 45: penalty += 0.0003\n",
        "        if self.soc < 10: penalty += 0.0002\n",
        "        self.health_score = clamp(self.health_score - penalty, 0.5, 1.0)\n",
        "\n",
        "        return {\n",
        "            \"schema_version\": SCHEMA_VERSION,\n",
        "            \"vehicle_id\": self.vehicle_id,\n",
        "            \"timestamp\": iso_now(),\n",
        "            \"metrics\": {\n",
        "                \"soc_pct\": round(self.soc, 2),\n",
        "                \"pack_voltage_v\": round(pack_v, 2),\n",
        "                \"pack_current_a\": round(pack_a, 2),\n",
        "                \"power_kw\": round(power_kw, 3),\n",
        "                \"battery_temp_c\": round(self.battery_temp, 2),\n",
        "                \"motor_temp_c\": round(self.motor_temp, 2),\n",
        "                \"coolant_temp_c\": round(self.coolant_temp, 2),\n",
        "                \"tyre_pressure_kpa\": [round(p, 1) for p in self.tyre_pressure_kpa],\n",
        "                \"speed_kph\": round(self.speed_kph, 2),\n",
        "                \"odometer_km\": round(self.odometer_km, 3),\n",
        "                \"latitude\": round(self.lat, 6),\n",
        "                \"longitude\": round(self.lon, 6),\n",
        "                \"heading_deg\": round(self.heading_deg, 1),\n",
        "                \"ambient_temp_c\": round(self.ambient_temp, 1),\n",
        "                \"is_charging\": self.is_charging,\n",
        "                \"charge_power_kw\": round(self.charge_power_kw, 2),\n",
        "                \"health_score\": round(self.health_score, 3),\n",
        "            },\n",
        "            \"events\": {\n",
        "                \"fault_code\": self.fault\n",
        "            }\n",
        "        }\n",
        "\n",
        "def make_vehicles(n, seed=None, base_lat=-23.5505, base_lon=-46.6333):\n",
        "    r = random.Random(seed)\n",
        "    return [EV(i+1,\n",
        "               base_lat=base_lat + r.uniform(-0.5, 0.5),\n",
        "               base_lon=base_lon + r.uniform(-0.5, 0.5),\n",
        "               seed=r.randrange(1<<30)) for i in range(n)]\n",
        "\n",
        "# ------- Sinks -------\n",
        "\n",
        "class StdoutSink:\n",
        "    def send(self, record: dict):\n",
        "        print(json.dumps(record, ensure_ascii=False), flush=True)\n",
        "    def close(self): pass\n",
        "\n",
        "class FileSink:\n",
        "    def __init__(self, path=\"telemetria.jsonl\"):\n",
        "        # Expande ~ e normaliza\n",
        "        p = os.path.expanduser(path)\n",
        "\n",
        "        # Se for diret√≥rio (existente ou terminar com /), usa nome padr√£o\n",
        "        if p.endswith(os.sep) or os.path.isdir(p):\n",
        "            os.makedirs(p, exist_ok=True)\n",
        "            p = os.path.join(p, \"telemetria.jsonl\")\n",
        "        else:\n",
        "            parent = os.path.dirname(p) or \".\"\n",
        "            os.makedirs(parent, exist_ok=True)\n",
        "\n",
        "        try:\n",
        "            self.f = open(p, \"a\", encoding=\"utf-8\", newline=\"\\n\")\n",
        "        except OSError as e:\n",
        "            raise RuntimeError(f\"N√£o consegui abrir '{p}': {e.strerror}\") from e\n",
        "\n",
        "        self.path = p\n",
        "\n",
        "    def send(self, record: dict):\n",
        "        self.f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "    def close(self):\n",
        "        self.f.flush()\n",
        "        self.f.close()\n",
        "\n",
        "class HTTPSink:\n",
        "    def __init__(self, url, bearer=None, timeout=5):\n",
        "        self.url = url; self.bearer = bearer; self.timeout = timeout\n",
        "    def send(self, record: dict):\n",
        "        data = json.dumps(record, ensure_ascii=False).encode(\"utf-8\")\n",
        "        headers = {\"Content-Type\": \"application/json\"}\n",
        "        if self.bearer: headers[\"Authorization\"] = f\"Bearer {self.bearer}\"\n",
        "        req = Request(self.url, data=data, headers=headers, method=\"POST\")\n",
        "        # retry leve\n",
        "        for attempt in range(3):\n",
        "            try:\n",
        "                with urlopen(req, timeout=self.timeout) as resp:\n",
        "                    if 200 <= resp.status < 300: return\n",
        "                    raise HTTPError(self.url, resp.status, \"HTTP error\", resp.headers, None)\n",
        "            except Exception as e:\n",
        "                if attempt == 2:\n",
        "                    print(f\"[WARN] Falha ao enviar: {e}\")\n",
        "                time.sleep(0.3 * (attempt+1))\n",
        "    def close(self): pass\n",
        "\n",
        "# Kafka √© opcional; s√≥ cria se a lib existir\n",
        "def _maybe_make_kafka_sink(topic, bootstrap_servers, **auth):\n",
        "    try:\n",
        "        from confluent_kafka import Producer\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(\"Kafka n√£o t√° dispon√≠vel. Vc pode instalar 'confluent-kafka' na c√©lula anterior.\") from e\n",
        "\n",
        "    conf = {\"bootstrap.servers\": bootstrap_servers, \"acks\": \"all\",\n",
        "            \"enable.idempotence\": True, \"linger.ms\": 20, \"compression.type\": \"zstd\"}\n",
        "    for k in (\"security.protocol\",\"sasl.mechanism\",\"sasl.username\",\"sasl.password\"):\n",
        "        if auth.get(k): conf[k] = auth[k]\n",
        "    prod = Producer(conf)\n",
        "    class KafkaSink:\n",
        "        def __init__(self, producer, topic):\n",
        "            self.p = producer; self.topic = topic\n",
        "        def send(self, record):\n",
        "            key = record[\"vehicle_id\"].encode(\"utf-8\")\n",
        "            val = json.dumps(record, ensure_ascii=False, separators=(\",\",\":\")).encode(\"utf-8\")\n",
        "            self.p.produce(self.topic, key=key, value=val)\n",
        "            self.p.poll(0)\n",
        "        def close(self):\n",
        "            self.p.flush(10)\n",
        "    return KafkaSink(prod, topic)\n",
        "\n",
        "# ------- \"API\" simples para Colab -------\n",
        "\n",
        "def simular_frota(\n",
        "    # --- simula√ß√£o ---\n",
        "    vehicles: int = 20,\n",
        "    hz: float = 1.0,\n",
        "    duration: int = 60,\n",
        "    seed: int | None = None,\n",
        "\n",
        "    # --- sink principal: 'stdout' | 'file' | 'http' | 'kafka' ---\n",
        "    sink: str = \"stdout\",\n",
        "\n",
        "    # file\n",
        "    file_path: str = \"telemetria.jsonl\",\n",
        "\n",
        "    # http\n",
        "    http_url: str | None = None,\n",
        "    http_bearer: str | None = None,\n",
        "\n",
        "    # kafka (telemetria bruta)\n",
        "    kafka_topic: str | None = None,\n",
        "    kafka_bootstrap: str | None = None,\n",
        "    kafka_security_protocol: str | None = None,   # ex: \"SASL_SSL\" | \"PLAINTEXT\"\n",
        "    kafka_sasl_mechanism: str | None = None,      # ex: \"PLAIN\"\n",
        "    kafka_sasl_username: str | None = None,\n",
        "    kafka_sasl_password: str | None = None,\n",
        "\n",
        "    # --- alertas ---\n",
        "    alert_threshold: float = 20.0,                # SOC < threshold => alerta\n",
        "    enable_kafka_alerts: bool = False,\n",
        "    kafka_alert_topic: str | None = None,         # t√≥pico s√≥ de alertas\n",
        "    enable_mongo_alerts: bool = False,\n",
        "    mongo_uri: str = \"mongodb://127.0.0.1:27017\", # no Colab local\n",
        "    mongo_db: str = \"telemetria\",\n",
        "    mongo_collection: str = \"ev_alerts\",\n",
        "    mongo_ttl_days: int | None = 30,\n",
        "):\n",
        "    \"\"\"\n",
        "    Simula EVs emitindo telemetria 'hz' vezes/s por 'duration' s.\n",
        "    Sink principal: 'stdout' | 'file' | 'http' | 'kafka'\n",
        "    Alertas: quando SOC < alert_threshold, envia para Kafka (t√≥pico de alertas) e/ou Mongo.\n",
        "    \"\"\"\n",
        "    if hz <= 0:\n",
        "        raise ValueError(\"hz deve ser > 0\")\n",
        "    if vehicles <= 0:\n",
        "        raise ValueError(\"vehicles deve ser > 0\")\n",
        "\n",
        "    random.seed(seed)\n",
        "    fleet = make_vehicles(vehicles, seed=seed)\n",
        "\n",
        "    # --- Seleciona o sink principal (telemetria bruta) ---\n",
        "    if      sink == \"stdout\":\n",
        "        s = StdoutSink()\n",
        "    elif    sink == \"file\":\n",
        "        s = FileSink(file_path)\n",
        "    elif    sink == \"http\":\n",
        "        if not http_url:\n",
        "            raise ValueError(\"Defina http_url para sink='http'\")\n",
        "        s = HTTPSink(http_url, bearer=http_bearer)\n",
        "    elif    sink == \"kafka\":\n",
        "        if not kafka_topic or not kafka_bootstrap:\n",
        "            raise ValueError(\"Defina kafka_topic e kafka_bootstrap para sink='kafka'\")\n",
        "        s = _maybe_make_kafka_sink(\n",
        "            topic=kafka_topic,\n",
        "            bootstrap_servers=kafka_bootstrap,\n",
        "            **{\n",
        "                \"security.protocol\": kafka_security_protocol,\n",
        "                \"sasl.mechanism\": kafka_sasl_mechanism,\n",
        "                \"sasl.username\": kafka_sasl_username,\n",
        "                \"sasl.password\": kafka_sasl_password,\n",
        "            }\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(\"sink inv√°lido. Use: 'stdout' | 'file' | 'http' | 'kafka'\")\n",
        "\n",
        "    # --- Sinks de alerta (apenas quando SOC < threshold) ---\n",
        "    alert_sinks = []\n",
        "    mongo_store = None\n",
        "    kafka_alert_sink = None\n",
        "\n",
        "    if enable_mongo_alerts:\n",
        "        # requer classe MongoAlertStore definida\n",
        "        mongo_store = MongoAlertStore(\n",
        "            uri=mongo_uri, db=mongo_db, collection=mongo_collection, ttl_days=mongo_ttl_days\n",
        "        )\n",
        "        alert_sinks.append(mongo_store)\n",
        "\n",
        "    if enable_kafka_alerts:\n",
        "        if not kafka_bootstrap:\n",
        "            raise ValueError(\"Defina kafka_bootstrap para alertas Kafka\")\n",
        "        if not kafka_alert_topic and not kafka_topic:\n",
        "            raise ValueError(\"Defina kafka_alert_topic (ou configure kafka_topic para usar o mesmo)\")\n",
        "        # usa kafka_alert_topic se dado; sen√£o cai pro kafka_topic\n",
        "        alert_topic = kafka_alert_topic or kafka_topic\n",
        "        kafka_alert_sink = _maybe_make_kafka_sink(\n",
        "            topic=alert_topic,\n",
        "            bootstrap_servers=kafka_bootstrap,\n",
        "            **{\n",
        "                \"security.protocol\": kafka_security_protocol,\n",
        "                \"sasl.mechanism\": kafka_sasl_mechanism,\n",
        "                \"sasl.username\": kafka_sasl_username,\n",
        "                \"sasl.password\": kafka_sasl_password,\n",
        "            }\n",
        "        )\n",
        "        alert_sinks.append(kafka_alert_sink)\n",
        "\n",
        "    # --- loop de emiss√£o ---\n",
        "    dt = 1.0 / hz\n",
        "    start = time.time()\n",
        "    try:\n",
        "        while True:\n",
        "            now = time.time()\n",
        "            if duration is not None and (now - start) >= duration:\n",
        "                break\n",
        "\n",
        "            tick_start = time.time()\n",
        "            for v in fleet:\n",
        "                rec = v.step(dt)\n",
        "\n",
        "                # telemetria bruta\n",
        "                s.send(rec)\n",
        "\n",
        "                # alertas (SOC baixo)\n",
        "                if rec[\"metrics\"][\"soc_pct\"] < alert_threshold:\n",
        "                    for asink in alert_sinks:\n",
        "                        asink.send(rec)\n",
        "\n",
        "            # manter frequ√™ncia aproximada\n",
        "            elapsed = time.time() - tick_start\n",
        "            sleep_time = max(0.0, dt - elapsed)\n",
        "            if sleep_time > 0:\n",
        "                time.sleep(sleep_time)\n",
        "    finally:\n",
        "        # fechar tudo com carinho\n",
        "        try: s.close()\n",
        "        except: pass\n",
        "        try:\n",
        "            if kafka_alert_sink: kafka_alert_sink.close()\n",
        "        except: pass\n",
        "        try:\n",
        "            if mongo_store: mongo_store.close()\n",
        "        except: pass\n"
      ],
      "metadata": {
        "id": "Hhe0mNO7YQd_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Simulando os dados**\n",
        "\n",
        "Foi simulado o seguinte cen√°rio:\n",
        "- 10 ve√≠culos sendo monitorados por 5 minutos\n",
        "- Coleta de sinais a cada 1 segundo (par√¢metro `hz`)\n",
        "\n",
        "√â poss√≠vel aumentar a quantidade de carros e tempo de simula√ß√£o para um volume de dados maior mas para uma quantidade de ve√≠culos acima de 50 e tempo de simula√ß√£o acima de 30 minutos a simula√ß√£o consume muito tempo e n√£o foi poss√≠vel simular cen√°rios mais complexos. Mas com tempo dispon√≠vel e recurso computacional √© poss√≠vel simular qualquer cen√°rio.\n",
        "\n"
      ],
      "metadata": {
        "id": "WoHEsaPbAiDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# simular_frota(vehicles=10, hz=1, duration=60, seed=42, sink=\"file\", file_path=\"/content/simulation_output/telemetria.jsonl\")\n",
        "\n",
        "# Se quiser baixar o json...\n",
        "#files.download(\"/content/simulation_output/telemetria.jsonl\")"
      ],
      "metadata": {
        "id": "zZuKhKmaZjie"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simular_frota(\n",
        "    vehicles=20, hz=2, duration=60,\n",
        "    sink=\"file\", file_path=\"out/telemetria/ev.jsonl\",\n",
        "    alert_threshold=60,\n",
        "    enable_mongo_alerts=True,\n",
        "    mongo_uri=\"mongodb://127.0.0.1:27017\",\n",
        "    mongo_db=\"telemetria\",\n",
        "    mongo_collection=\"ev_alerts\",\n",
        "    mongo_ttl_days=30,   # ou None para n√£o expirar\n",
        ")"
      ],
      "metadata": {
        "id": "HFq4umlKL8pt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verificando alertas armazenados no MongoDB"
      ],
      "metadata": {
        "id": "ecwvB5XoOWGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pymongo import MongoClient\n",
        "cli = MongoClient(\"mongodb://127.0.0.1:27017\")\n",
        "col = cli[\"telemetria\"][\"ev_alerts\"]\n",
        "print(\"Total de alertas:\", col.count_documents({}))\n",
        "for d in col.find({}, {\"_id\":0,\"ts\":1,\"vehicle_id\":1,\"soc_pct\":1}).sort(\"ts_dt\",-1).limit(5):\n",
        "    print(d)\n",
        "cli.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2PyJ16aORVM",
        "outputId": "93a7e3c7-3904-4d71-d813-abd3dc24f756"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de alertas: 840\n",
            "{'ts': '2025-08-24T23:10:49.963275+00:00', 'vehicle_id': 'EV-00019', 'soc_pct': 47.16}\n",
            "{'ts': '2025-08-24T23:10:49.962432+00:00', 'vehicle_id': 'EV-00016', 'soc_pct': 5.29}\n",
            "{'ts': '2025-08-24T23:10:49.961572+00:00', 'vehicle_id': 'EV-00014', 'soc_pct': 56.66}\n",
            "{'ts': '2025-08-24T23:10:49.959631+00:00', 'vehicle_id': 'EV-00001', 'soc_pct': 54.29}\n",
            "{'ts': '2025-08-24T23:10:49.463072+00:00', 'vehicle_id': 'EV-00019', 'soc_pct': 47.16}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pipeline de Telemetria**\n",
        "\n",
        "O c√≥digo abaixo implementa um fluxo de ingest√£o, tratamento e curadoria de dados de telemetria de carros el√©tricos usando PySpark em modo batch.\n",
        "\n",
        "# **Arquitetura L√≥gica**\n",
        "\n",
        "O pipeline segue as seguintes fases:\n",
        "\n",
        "1. **Ingest√£o** ‚Üí leitura de dados brutos (CSV, JSON, Parquet).\n",
        "2. **Padroniza√ß√£o** ‚Üí ajuste de tipos, normaliza√ß√£o de colunas e timezone.\n",
        "3. **Tratamento** ‚Üí regras de qualidade, remo√ß√£o de duplicidades e checagem de dom√≠nios.\n",
        "4. **Enriquecimento** ‚Üí cria√ß√£o de colunas derivadas e parti√ß√µes.\n",
        "5. **Valida√ß√£o** ‚Üí c√°lculos de m√©tricas de qualidade e estat√≠sticas b√°sicas.\n",
        "6. **Grava√ß√£o** ‚Üí escrita em **Parquet particionado (ano, mes)** com compress√£o Snappy.\n",
        "7. **Metadados** ‚Üí registro de dicion√°rio de dados e log de execu√ß√£o.\n",
        "8. **Cat√°logo (opcional)** ‚Üí integra√ß√£o com Hive Metastore ou Glue.\n",
        "\n",
        "\n",
        "# **Explica√ß√£o das Etapas**\n",
        "\n",
        "## 1. Ingest√£o\n",
        "- **O que faz**: l√™ os arquivos brutos em JSON, CSV ou Parquet.  \n",
        "- **Detalhes**:  \n",
        "  - JSON ‚Üí utiliza `RAW_SCHEMA` expl√≠cito (campos nested).  \n",
        "  - CSV ‚Üí l√™ schema flat e reconstr√≥i a estrutura.  \n",
        "  - Parquet ‚Üí j√° otimizado, com `mergeSchema` habilitado.  \n",
        "\n",
        "## 2. Padroniza√ß√£o\n",
        "- **O que faz**: normaliza colunas e converte timestamps.  \n",
        "- **A√ß√µes principais**:  \n",
        "  - Converte `timestamp` em `event_ts_utc` (ISO8601 ‚Üí Spark timestamp).  \n",
        "  - Achata colunas de `metrics` e `events` em colunas simples.  \n",
        "  - Uniformiza encoding e tipos num√©ricos.  \n",
        "\n",
        "## 3. Tratamento e Qualidade\n",
        "- **O que faz**: aplica regras de qualidade sobre os dados.  \n",
        "- **Valida√ß√µes inclu√≠das**:  \n",
        "  - **Nulidade obrigat√≥ria** ‚Üí `vehicle_id`, `event_ts_utc`.  \n",
        "  - **Duplicidades** ‚Üí registros duplicados pela chave `(vehicle_id, event_ts_utc)` s√£o eliminados.  \n",
        "  - **Dom√≠nios v√°lidos** ‚Üí ex.: `soc_pct` (0‚Äì100), `latitude` (-90‚Äì90).  \n",
        "  - **Outliers** ‚Üí marcados via m√©todo IQR (Interquartile Range).  \n",
        "\n",
        "## 4. Enriquecimento\n",
        "- **O que faz**: adiciona colunas derivadas √∫teis para an√°lises.  \n",
        "- **Colunas criadas**:  \n",
        "  - `ano`, `mes`, `dia`, `hora` ‚Üí parti√ß√µes temporais.  \n",
        "  - `is_low_soc` ‚Üí flag de bateria baixa (< 20%).  \n",
        "  - `battery_temp_band` ‚Üí faixa de temperatura (low, normal, high).  \n",
        "  - `vehicle_ts_key` ‚Üí chave de neg√≥cio (`vehicle_id#timestamp`).  \n",
        "\n",
        "## 5. Valida√ß√£o\n",
        "- **O que faz**: calcula m√©tricas de qualidade dos dados processados.  \n",
        "- **M√©tricas registradas**:  \n",
        "  - Total de linhas processadas.  \n",
        "  - Quantidade de registros limpos vs. em quarentena.  \n",
        "  - % de registros v√°lidos.  \n",
        "  - KPIs espec√≠ficos (ex.: n¬∫ de registros com `soc_pct < 20`).  \n",
        "\n",
        "## 6. Grava√ß√£o\n",
        "- **O que faz**: persiste os dados tratados em Parquet particionado.  \n",
        "- **Configura√ß√µes**:  \n",
        "  - Particionado por `ano` e `mes`.  \n",
        "  - Compress√£o **Snappy**.  \n",
        "  - Modo de escrita configur√°vel:  \n",
        "    - `append` (default)  \n",
        "    - `overwrite` (reprocesso completo)  \n",
        "    - `overwrite_partitions` (din√¢mico, substitui apenas parti√ß√µes tocadas).  \n",
        "\n",
        "## 7. Metadados\n",
        "- **Arquivos gerados** em `_metadata/`:  \n",
        "  - `dicionario_dados.json` ‚Üí descreve cada coluna (nome, tipo, nulabilidade).  \n",
        "  - `exec_log.json` ‚Üí log de execu√ß√£o contendo:  \n",
        "    - Caminhos de entrada/sa√≠da.  \n",
        "    - Hor√°rio de in√≠cio/fim do job.  \n",
        "    - M√©tricas de qualidade.  \n",
        "    - Vers√£o do Spark usada.  \n",
        "\n",
        "## 8. Cat√°logo\n",
        "- **O que faz**: registra o dataset curado no Hive Metastore ou AWS Glue.  "
      ],
      "metadata": {
        "id": "8eD1iimwA_Rz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criando o pipeline"
      ],
      "metadata": {
        "id": "1AmAvufrAyFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# Pipeline da telemetria dos carros el√©tricos\n",
        "# ================================\n",
        "# Requisitos:\n",
        "#   - Spark 3.x\n",
        "#   - Conectores adequados para S3, ADLS, GCS se usar nuvem.\n",
        "#   - Para schema evolution simples em Parquet: mergeSchema (leitura) + unionByName(allowMissingColumns=True)\n",
        "#\n",
        "# Sa√≠das:\n",
        "#   - Parquet particionado por ano/mes (compress√£o Snappy)\n",
        "#   - dicionario_dados.json (schema final) em /content/pipeline_output/_metadata\n",
        "#   - exec_log.json (m√©tricas/linhagem simples) em /content/pipeline_output/_metadata\n",
        "\n",
        "from pyspark.sql import SparkSession, DataFrame\n",
        "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, ArrayType, BooleanType\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.window import Window\n",
        "import json, math, random, time, os, sys, re\n",
        "from datetime import datetime, timezone\n",
        "from urllib.parse import urlparse\n",
        "from urllib.request import Request, urlopen\n",
        "from urllib.error import URLError, HTTPError\n",
        "from google.colab import files\n",
        "from typing import Dict, List, Tuple\n",
        "from datetime import datetime, timezone\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Configura√ß√£o Spark\n",
        "# -------------------------\n",
        "def build_spark(app_name=\"EV_Telemetry_Batch\"):\n",
        "    spark = (\n",
        "        SparkSession.builder\n",
        "        .appName(app_name)\n",
        "        # Parquet + compress√£o\n",
        "        .config(\"spark.sql.parquet.compression.codec\", \"snappy\")\n",
        "        # Evolu√ß√£o de schema na leitura (mesclar schemas de arquivos)\n",
        "        .config(\"spark.sql.parquet.mergeSchema\", \"true\")\n",
        "        # Overwrite din√¢mico de parti√ß√µes\n",
        "        .config(\"spark.sql.sources.partitionOverwriteMode\", \"dynamic\")\n",
        "        # Shuffle e AQE para jobs maiores (opcional)\n",
        "        .config(\"spark.sql.adaptive.enabled\", \"true\")\n",
        "        .getOrCreate()\n",
        "    )\n",
        "    return spark\n",
        "\n",
        "# -------------------------\n",
        "# Descoberta: Schema de entrada\n",
        "# -------------------------\n",
        "# Schema expl√≠cito (aninhado) compat√≠vel com o simulador JSON/Parquet\n",
        "RAW_SCHEMA = StructType([\n",
        "    StructField(\"schema_version\", StringType(), True),\n",
        "    StructField(\"vehicle_id\", StringType(), True),\n",
        "    StructField(\"timestamp\", StringType(), True),\n",
        "    StructField(\"metrics\", StructType([\n",
        "        StructField(\"soc_pct\", DoubleType(), True),\n",
        "        StructField(\"pack_voltage_v\", DoubleType(), True),\n",
        "        StructField(\"pack_current_a\", DoubleType(), True),\n",
        "        StructField(\"power_kw\", DoubleType(), True),\n",
        "        StructField(\"battery_temp_c\", DoubleType(), True),\n",
        "        StructField(\"motor_temp_c\", DoubleType(), True),\n",
        "        StructField(\"coolant_temp_c\", DoubleType(), True),\n",
        "        StructField(\"tyre_pressure_kpa\", ArrayType(DoubleType()), True),\n",
        "        StructField(\"speed_kph\", DoubleType(), True),\n",
        "        StructField(\"odometer_km\", DoubleType(), True),\n",
        "        StructField(\"latitude\", DoubleType(), True),\n",
        "        StructField(\"longitude\", DoubleType(), True),\n",
        "        StructField(\"heading_deg\", DoubleType(), True),\n",
        "        StructField(\"ambient_temp_c\", DoubleType(), True),\n",
        "        StructField(\"is_charging\", BooleanType(), True),\n",
        "        StructField(\"charge_power_kw\", DoubleType(), True),\n",
        "        StructField(\"health_score\", DoubleType(), True),\n",
        "    ]), True),\n",
        "    StructField(\"events\", StructType([\n",
        "        StructField(\"fault_code\", StringType(), True),\n",
        "    ]), True),\n",
        "])\n",
        "\n",
        "# Para CSV (flat) ‚Äì caso o(s) CSV(s) j√° venha(m) \"achatados\"\n",
        "CSV_FLAT_SCHEMA = StructType([\n",
        "    StructField(\"schema_version\", StringType(), True),\n",
        "    StructField(\"vehicle_id\", StringType(), True),\n",
        "    StructField(\"timestamp\", StringType(), True),\n",
        "    StructField(\"soc_pct\", DoubleType(), True),\n",
        "    StructField(\"pack_voltage_v\", DoubleType(), True),\n",
        "    StructField(\"pack_current_a\", DoubleType(), True),\n",
        "    StructField(\"power_kw\", DoubleType(), True),\n",
        "    StructField(\"battery_temp_c\", DoubleType(), True),\n",
        "    StructField(\"motor_temp_c\", DoubleType(), True),\n",
        "    StructField(\"coolant_temp_c\", DoubleType(), True),\n",
        "    StructField(\"tyre_pressure_kpa\", StringType(), True), # CSV pode trazer como string \"[]\"\n",
        "    StructField(\"speed_kph\", DoubleType(), True),\n",
        "    StructField(\"odometer_km\", DoubleType(), True),\n",
        "    StructField(\"latitude\", DoubleType(), True),\n",
        "    StructField(\"longitude\", DoubleType(), True),\n",
        "    StructField(\"heading_deg\", DoubleType(), True),\n",
        "    StructField(\"ambient_temp_c\", DoubleType(), True),\n",
        "    StructField(\"is_charging\", StringType(), True),       # \"true\"/\"false\"\n",
        "    StructField(\"charge_power_kw\", DoubleType(), True),\n",
        "    StructField(\"health_score\", DoubleType(), True),\n",
        "    StructField(\"fault_code\", StringType(), True),\n",
        "])\n",
        "\n",
        "# -------------------------\n",
        "# Auxiliares\n",
        "# -------------------------\n",
        "def infer_format_from_path(path: str) -> str:\n",
        "    path = path.lower()\n",
        "    if path.endswith(\".json\") or path.endswith(\".jsonl\"): return \"json\"\n",
        "    if path.endswith(\".csv\"): return \"csv\"\n",
        "    if path.endswith(\".parquet\"): return \"parquet\"\n",
        "    # se for diret√≥rio com m√∫ltiplos arquivos, confie no par√¢metro do usu√°rio\n",
        "    return None\n",
        "\n",
        "def parse_boolean_col(col):\n",
        "    # converte strings \"true\"/\"false\"/\"1\"/\"0\" para boolean\n",
        "    return (\n",
        "        F.when(F.col(col).cast(\"boolean\").isNotNull(), F.col(col).cast(\"boolean\"))\n",
        "         .when(F.lower(F.col(col)).isin(\"true\",\"t\",\"1\",\"yes\",\"y\"), F.lit(True))\n",
        "         .when(F.lower(F.col(col)).isin(\"false\",\"f\",\"0\",\"no\",\"n\"), F.lit(False))\n",
        "         .otherwise(F.lit(None))\n",
        "    )\n",
        "\n",
        "# -------------------------\n",
        "# 1) Ingest√£o\n",
        "# -------------------------\n",
        "def read_raw(spark: SparkSession, input_path: str, input_format: str = None) -> DataFrame:\n",
        "    fmt = input_format or infer_format_from_path(input_path) or \"json\"\n",
        "\n",
        "    if fmt == \"json\":\n",
        "        df = (spark.read\n",
        "              .format(\"json\")\n",
        "              .schema(RAW_SCHEMA)\n",
        "              .option(\"multiLine\", \"false\")\n",
        "              .load(input_path))\n",
        "    elif fmt == \"parquet\":\n",
        "        # leitura com mergeSchema habilitado (builder j√° tem mergeSchema=true)\n",
        "        df = spark.read.schema(RAW_SCHEMA).parquet(input_path)\n",
        "    elif fmt == \"csv\":\n",
        "        # CSV flat (sem nested). Ajuste separador se necess√°rio.\n",
        "        df = (spark.read\n",
        "              .format(\"csv\")\n",
        "              .option(\"header\", \"true\")\n",
        "              .option(\"mode\", \"PERMISSIVE\")\n",
        "              .schema(CSV_FLAT_SCHEMA)\n",
        "              .load(input_path))\n",
        "        # Reconstr√≥i estrutura nested como no JSON\n",
        "        df = (\n",
        "            df.withColumn(\"tyre_pressure_kpa\",\n",
        "                          F.when(F.col(\"tyre_pressure_kpa\").isNull(), F.array().cast(\"array<double>\"))\n",
        "                           .otherwise(F.from_json(\"tyre_pressure_kpa\", ArrayType(DoubleType()))))\n",
        "              .withColumn(\"is_charging\", parse_boolean_col(\"is_charging\"))\n",
        "              .withColumn(\"metrics\", F.struct(\n",
        "                    \"soc_pct\",\"pack_voltage_v\",\"pack_current_a\",\"power_kw\",\n",
        "                    \"battery_temp_c\",\"motor_temp_c\",\"coolant_temp_c\",\n",
        "                    \"tyre_pressure_kpa\",\"speed_kph\",\"odometer_km\",\n",
        "                    \"latitude\",\"longitude\",\"heading_deg\",\"ambient_temp_c\",\n",
        "                    \"is_charging\",\"charge_power_kw\",\"health_score\"\n",
        "              ))\n",
        "              .withColumn(\"events\", F.struct(\"fault_code\"))\n",
        "              .select(\"schema_version\",\"vehicle_id\",\"timestamp_parsed\",\"metrics\",\"events\")\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(f\"Formato n√£o suportado: {fmt}\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# -------------------------\n",
        "# 2) Padroniza√ß√£o\n",
        "# -------------------------\n",
        "def standardize(df: DataFrame, tz_source=\"UTC\", tz_target=\"UTC\") -> DataFrame:\n",
        "    # timestamp ISO8601 ‚Üí timestamp (UTC)\n",
        "    # se precisar converter TZ diferente, aplique from_utc_timestamp/to_utc_timestamp conforme origem\n",
        "    df = df.withColumn(\"timestamp_parsed\", F.to_timestamp(F.col(\"timestamp\")))\n",
        "\n",
        "    # Normaliza colunas (achatar metrics/events)\n",
        "    df = df.select(\n",
        "        \"schema_version\",\"vehicle_id\",\"timestamp_parsed\",\n",
        "        F.col(\"metrics.soc_pct\").alias(\"soc_pct\"),\n",
        "        F.col(\"metrics.pack_voltage_v\").alias(\"pack_voltage_v\"),\n",
        "        F.col(\"metrics.pack_current_a\").alias(\"pack_current_a\"),\n",
        "        F.col(\"metrics.power_kw\").alias(\"power_kw\"),\n",
        "        F.col(\"metrics.battery_temp_c\").alias(\"battery_temp_c\"),\n",
        "        F.col(\"metrics.motor_temp_c\").alias(\"motor_temp_c\"),\n",
        "        F.col(\"metrics.coolant_temp_c\").alias(\"coolant_temp_c\"),\n",
        "        F.col(\"metrics.tyre_pressure_kpa\").alias(\"tyre_pressure_kpa\"),\n",
        "        F.col(\"metrics.speed_kph\").alias(\"speed_kph\"),\n",
        "        F.col(\"metrics.odometer_km\").alias(\"odometer_km\"),\n",
        "        F.col(\"metrics.latitude\").alias(\"latitude\"),\n",
        "        F.col(\"metrics.longitude\").alias(\"longitude\"),\n",
        "        F.col(\"metrics.heading_deg\").alias(\"heading_deg\"),\n",
        "        F.col(\"metrics.ambient_temp_c\").alias(\"ambient_temp_c\"),\n",
        "        F.col(\"metrics.is_charging\").alias(\"is_charging\"),\n",
        "        F.col(\"metrics.charge_power_kw\").alias(\"charge_power_kw\"),\n",
        "        F.col(\"metrics.health_score\").alias(\"health_score\"),\n",
        "        F.col(\"events.fault_code\").alias(\"fault_code\"),\n",
        "    )\n",
        "\n",
        "    # timezone: j√° em UTC; se viesse em outro fuso ia ser convertido aqui\n",
        "    df = df.withColumnRenamed(\"timestamp_parsed\", \"event_ts_utc\")\n",
        "\n",
        "    return df\n",
        "\n",
        "# -------------------------\n",
        "# 3) Tratamento\n",
        "# -------------------------\n",
        "MANDATORY = [\"vehicle_id\",\"event_ts_utc\"]\n",
        "\n",
        "# Fonte dos dom√≠nio baseado nos dom√≠nios do simulador\n",
        "# Algins intervalos foram criados propositalmente para serem identificados nesta etapas\n",
        "DOMAINS = {\n",
        "    \"soc_pct\": (0, 100),\n",
        "    \"battery_temp_c\": (18, 28),\n",
        "    \"motor_temp_c\": (20, 35),\n",
        "    \"coolant_temp_c\": (18, 25),\n",
        "    \"speed_kph\": (0.0, 25),\n",
        "    \"latitude\": (-90.0, 90.0), # Aqui fica dif√≠cil gerar um intervalo j√° que no simulador tudo √© gerado a partir de uma distribui√ß√£o uniforme\n",
        "    \"longitude\": (-180.0, 180.0), # Aqui fica dif√≠cil gerar um intervalo j√° que no simulador tudo √© gerado a partir de uma distribui√ß√£o uniforme\n",
        "    \"heading_deg\": (0.0, 360.0),\n",
        "    \"health_score\": (0.0, 1.0),\n",
        "    \"pack_voltage_v\": (200.0, 900.0),\n",
        "    \"pack_current_a\": (-2000.0, 2000.0),\n",
        "    \"power_kw\": (-300.0, 300.0),\n",
        "    \"charge_power_kw\": (0.0, 400.0),\n",
        "    \"odometer_km\": (0.0, 2_000_000.0),\n",
        "    \"ambient_temp_c\": (0, 30),\n",
        "}\n",
        "\n",
        "def with_quality_flags(df: DataFrame) -> Tuple[DataFrame, DataFrame]:\n",
        "    # Nulidade obrigat√≥ria\n",
        "    for c in MANDATORY:\n",
        "        df = df.withColumn(f\"q_not_null__{c}\", F.col(c).isNotNull())\n",
        "\n",
        "    # Tipagem: tenta cast \"seguro\" (n√£o deve alterar pois j√° padronizado)\n",
        "    # Dom√≠nio: flag ok_range_<col>\n",
        "    for c, (lo, hi) in DOMAINS.items():\n",
        "        if c in df.columns:\n",
        "            df = df.withColumn(f\"q_range__{c}\", (F.col(c) >= F.lit(lo)) & (F.col(c) <= F.lit(hi)))\n",
        "\n",
        "    # Duplicidade (chave l√≥gica vehicle_id+event_ts_utc)\n",
        "    w = Window.partitionBy(\"vehicle_id\",\"event_ts_utc\").orderBy(F.col(\"event_ts_utc\"))\n",
        "    df = df.withColumn(\"rownum_key\", F.row_number().over(w))\n",
        "    df = df.withColumn(\"q_is_duplicate\", F.col(\"rownum_key\") > 1)\n",
        "\n",
        "    # Outliers simples por amplitude interquartil em algumas m√©tricas (opcional)\n",
        "    # Existem outros m√©todos de detec√ß√£o de outliers (Regress√£o, Isolation Forest, Z-Score, etc)\n",
        "    # Coloquei o mais simples s√≥ como exemplo\n",
        "    numeric_cols = [c for c,t in df.dtypes if t in (\"double\",\"float\",\"int\",\"bigint\") and c in [\"soc_pct\",\"speed_kph\",\"battery_temp_c\",\"motor_temp_c\",\"power_kw\"]]\n",
        "    for c in numeric_cols:\n",
        "        # calcula IQR por job (n√£o por ve√≠culo) ‚Äì para simplificar\n",
        "        stats = df.select(\n",
        "            F.expr(f\"percentile({c}, array(0.25, 0.75))\").alias(\"q\")\n",
        "        ).first()\n",
        "        if stats and stats.q and len(stats.q) == 2:\n",
        "            q1, q3 = stats.q\n",
        "            iqr = q3 - q1\n",
        "            lo = q1 - 1.5*iqr\n",
        "            hi = q3 + 1.5*iqr\n",
        "            df = df.withColumn(f\"q_iqr__{c}\", (F.col(c) >= F.lit(lo)) & (F.col(c) <= F.lit(hi)))\n",
        "        else:\n",
        "            df = df.withColumn(f\"q_iqr__{c}\", F.lit(True))\n",
        "\n",
        "    # Quarentena de registros ruins (nulos obrigat√≥rios, fora de dom√≠nio, duplicados)\n",
        "    quality_cols = [c for c in df.columns if c.startswith(\"q_\")]\n",
        "    any_bad = ~F.array_min(F.array([F.col(c).cast(\"boolean\") for c in quality_cols if not c.startswith(\"q_is_duplicate\")]))\n",
        "    quarantine = df.filter(any_bad | F.col(\"q_is_duplicate\"))\n",
        "\n",
        "    # Dados limpos: remove duplicados mantendo a 1¬™ ocorr√™ncia e filtra por dom√≠nios obrigat√≥rios\n",
        "    clean = df.filter(~F.col(\"q_is_duplicate\"))\n",
        "    for c in MANDATORY:\n",
        "        clean = clean.filter(F.col(c).isNotNull())\n",
        "    for c,(lo,hi) in DOMAINS.items():\n",
        "        if c in clean.columns:\n",
        "            clean = clean.filter((F.col(c) >= lo) & (F.col(c) <= hi))\n",
        "\n",
        "    clean = clean.drop(\"rownum_key\")\n",
        "\n",
        "    return clean, quarantine\n",
        "\n",
        "# -------------------------\n",
        "# 4) Enriquecimento\n",
        "# -------------------------\n",
        "def enrich(df: DataFrame) -> DataFrame:\n",
        "    # Deriva data/hora e parti√ß√µes\n",
        "    df = (df\n",
        "          .withColumn(\"event_date\", F.to_date(\"event_ts_utc\"))\n",
        "          .withColumn(\"ano\", F.year(\"event_ts_utc\"))\n",
        "          .withColumn(\"mes\", F.month(\"event_ts_utc\"))\n",
        "          .withColumn(\"dia\", F.dayofmonth(\"event_ts_utc\"))\n",
        "          .withColumn(\"hora\", F.hour(\"event_ts_utc\"))\n",
        "          # flags √∫teis\n",
        "          .withColumn(\"is_low_soc\", F.col(\"soc_pct\") < 60)\n",
        "          .withColumn(\"battery_temp_band\",\n",
        "                      F.when(F.col(\"battery_temp_c\") < 10, F.lit(\"low\"))\n",
        "                       .when(F.col(\"battery_temp_c\") <= 45, F.lit(\"normal\"))\n",
        "                       .otherwise(F.lit(\"high\")))\n",
        "          # chave de neg√≥cio (se quiser chave inteira)\n",
        "          .withColumn(\"vehicle_ts_key\", F.concat_ws(\"#\", F.col(\"vehicle_id\"), F.col(\"event_ts_utc\").cast(\"string\")))\n",
        "    )\n",
        "    return df\n",
        "\n",
        "# -------------------------\n",
        "# 5) Valida√ß√£o\n",
        "# -------------------------\n",
        "def compute_quality_metrics(clean: DataFrame, quarantine: DataFrame) -> Dict:\n",
        "    total = clean.count() + quarantine.count()\n",
        "    m = {\n",
        "        \"total_input_rows\": total,\n",
        "        \"clean_rows\": clean.count(),\n",
        "        \"quarantine_rows\": quarantine.count(),\n",
        "        \"pct_clean\": float((clean.count() / total) * 100.0) if total else 0.0,\n",
        "        \"pct_quarantine\": float((quarantine.count() / total) * 100.0) if total else 0.0,\n",
        "    }\n",
        "    # Exemplo de m√©tricas por dom√≠nio\n",
        "    if \"is_low_soc\" in clean.columns:\n",
        "        low_soc = clean.filter(\"is_low_soc = true\").count()\n",
        "        m[\"low_soc_rows\"] = low_soc\n",
        "    return m\n",
        "\n",
        "# -------------------------\n",
        "# 6) Grava√ß√£o\n",
        "# -------------------------\n",
        "def write_parquet(\n",
        "    df_new: DataFrame,\n",
        "    output_path: str,\n",
        "    mode: str = \"append\",  # op√ß√µes: append, overwrite, overwrite_partitions\n",
        "    partition_cols: List[str] = [\"ano\",\"mes\"],\n",
        "):\n",
        "    writer = df_new.write.mode(\"append\").option(\"compression\",\"snappy\")\n",
        "    if mode == \"overwrite\":\n",
        "        writer = df_new.write.mode(\"overwrite\").option(\"compression\",\"snappy\")\n",
        "    elif mode == \"overwrite_partitions\":\n",
        "        # dynamic partition overwrite j√° habilitado via conf\n",
        "        writer = df_new.write.mode(\"overwrite\").option(\"compression\",\"snappy\")\n",
        "\n",
        "    (writer\n",
        "     .partitionBy(*partition_cols)\n",
        "     .parquet(output_path)\n",
        "    )\n",
        "\n",
        "# Evolu√ß√£o de schema simples: unir novo com existente por nome (permitindo colunas faltantes)\n",
        "def merge_with_existing_if_any(spark: SparkSession, df_new: DataFrame, output_path: str) -> DataFrame:\n",
        "    try:\n",
        "        df_old = spark.read.parquet(output_path)\n",
        "        # union por nome com colunas ausentes\n",
        "        df_merged = df_old.unionByName(df_new, allowMissingColumns=True)\n",
        "        # removemos duplicados chave (se houver) ‚Äì custo extra, opcional\n",
        "        if {\"vehicle_id\",\"event_ts_utc\"} <= set(df_merged.columns):\n",
        "            df_merged = df_merged.dropDuplicates([\"vehicle_id\",\"event_ts_utc\"])\n",
        "        return df_merged\n",
        "    except Exception:\n",
        "        # primeira carga\n",
        "        return df_new\n",
        "\n",
        "# -------------------------\n",
        "# 7) Metadados\n",
        "# -------------------------\n",
        "def schema_to_dict(df: DataFrame) -> List[Dict]:\n",
        "    out = []\n",
        "    for f in df.schema.fields:\n",
        "        out.append({\n",
        "            \"name\": f.name,\n",
        "            \"type\": f.dataType.simpleString(),\n",
        "            \"nullable\": f.nullable,\n",
        "            \"metadata\": dict(f.metadata) if f.metadata else {},\n",
        "        })\n",
        "    return out\n",
        "\n",
        "def write_metadata_files(spark: SparkSession, output_path: str, dict_schema: List[Dict], exec_log: Dict):\n",
        "    meta_path = output_path.rstrip(\"/\") + \"/_metadata\"\n",
        "    # dicion√°rio de dados\n",
        "    (spark.createDataFrame([json.dumps(dict_schema)], \"string\")\n",
        "          .toDF(\"json\")\n",
        "          .write.mode(\"overwrite\").text(meta_path + \"/dicionario_dados.json\"))\n",
        "    # log de execu√ß√£o\n",
        "    (spark.createDataFrame([json.dumps(exec_log)], \"string\")\n",
        "          .toDF(\"json\")\n",
        "          .write.mode(\"overwrite\").text(meta_path + \"/exec_log.json\"))\n",
        "\n",
        "# -------------------------\n",
        "# 8) Cat√°logo (opcoisnal)\n",
        "# -------------------------\n",
        "def register_in_catalog(spark: SparkSession, table_name: str, location: str):\n",
        "    spark.sql(f\"CREATE TABLE IF NOT EXISTS {table_name} USING parquet LOCATION '{location}'\")\n",
        "\n",
        "# -------------------------\n",
        "# Orquestra√ß√£o do Job\n",
        "# -------------------------\n",
        "\n",
        "from datetime import datetime, timezone, date as _date\n",
        "\n",
        "try:\n",
        "    from pymongo import MongoClient\n",
        "    _HAS_PYMONGO = True\n",
        "except Exception:\n",
        "    _HAS_PYMONGO = False\n",
        "\n",
        "class MongoMetricsStore:\n",
        "    def __init__(self, uri: str, db: str = \"telemetria\",\n",
        "                 coll_job: str = \"pipeline_runs\",\n",
        "                 ttl_days: int | None = None):\n",
        "        if not _HAS_PYMONGO:\n",
        "            raise RuntimeError(\"pymongo n√£o instalado. Rode: !pip install pymongo\")\n",
        "        self.client = MongoClient(uri, serverSelectionTimeoutMS=5000)\n",
        "        self.client.admin.command(\"ping\")\n",
        "        self.db = self.client[db]\n",
        "        self.col_job = self.db[coll_job]\n",
        "        # √≠ndices √∫teis\n",
        "        self.col_job.create_index([(\"job_name\", 1), (\"job_start_utc\", -1)])\n",
        "        if ttl_days and ttl_days > 0:\n",
        "            self.col_job.create_index(\"job_end_dt\", expireAfterSeconds=int(ttl_days*86400))\n",
        "\n",
        "    def write_job_metrics(self, exec_log: dict, metrics: dict, extra: dict | None = None):\n",
        "        # cria campo datetime 'naive' em UTC pra TTL\n",
        "        try:\n",
        "            dt = datetime.fromisoformat(exec_log[\"job_end_utc\"])\n",
        "            if dt.tzinfo: dt = dt.astimezone(timezone.utc).replace(tzinfo=None)\n",
        "        except Exception:\n",
        "            dt = None\n",
        "        doc = {\"job_end_dt\": dt, \"metrics\": metrics, **exec_log}\n",
        "        if extra: doc[\"extra\"] = extra\n",
        "        self.col_job.insert_one(doc)\n",
        "\n",
        "    def close(self):\n",
        "        try: self.client.close()\n",
        "        except: pass\n",
        "\n",
        "\n",
        "def compute_daily_vehicle_metrics(df: DataFrame) -> DataFrame:\n",
        "    # resumo por ve√≠culo/data para dashboard\n",
        "    return (df.groupBy(\"vehicle_id\", \"event_date\")\n",
        "              .agg(\n",
        "                  F.count(\"*\").alias(\"rows\"),\n",
        "                  F.min(\"soc_pct\").alias(\"soc_min\"),\n",
        "                  F.expr(\"percentile_approx(soc_pct, 0.5)\").alias(\"soc_p50\"),\n",
        "                  F.max(\"soc_pct\").alias(\"soc_max\"),\n",
        "                  F.sum(F.when(F.col(\"is_low_soc\"), 1).otherwise(0)).alias(\"low_soc_cnt\"),\n",
        "                  F.avg(\"speed_kph\").alias(\"speed_avg\")\n",
        "              ))\n",
        "\n",
        "def insert_dataframe_to_mongo(df_agg: DataFrame, uri: str,\n",
        "                              db: str = \"telemetria\",\n",
        "                              collection: str = \"ev_metrics_daily\",\n",
        "                              batch_size: int = 1000):\n",
        "    if not _HAS_PYMONGO:\n",
        "        raise RuntimeError(\"pymongo n√£o instalado. Rode: !pip install pymongo\")\n",
        "    client = MongoClient(uri, serverSelectionTimeoutMS=5000)\n",
        "    client.admin.command(\"ping\")\n",
        "    col = client[db][collection]\n",
        "    # √≠ndice para consultas\n",
        "    col.create_index([(\"vehicle_id\", 1), (\"event_date\", -1)])\n",
        "\n",
        "    buf = []\n",
        "    def _flush():\n",
        "        if buf:\n",
        "            col.insert_many(buf)\n",
        "            buf.clear()\n",
        "\n",
        "    for row in df_agg.toLocalIterator():  # stream pra n√£o estourar mem√≥ria\n",
        "        d = row.asDict(recursive=True)\n",
        "        # event_date vem como datetime.date -> salva ISO string (simples p/ queries)\n",
        "        if isinstance(d.get(\"event_date\"), _date):\n",
        "            d[\"event_date\"] = d[\"event_date\"].isoformat()\n",
        "        buf.append(d)\n",
        "        if len(buf) >= batch_size:\n",
        "            _flush()\n",
        "    _flush()\n",
        "    client.close()\n",
        "\n",
        "def run_job(\n",
        "    input_path: str,\n",
        "    output_path: str,\n",
        "    input_format: str = None,     # \"json\"|\"csv\"|\"parquet\"|None(auto por extens√£o)\n",
        "    mode: str = \"append\",         # append|overwrite|overwrite_partitions\n",
        "    register_table: str = None,   # ex: \"ev.blah_telemetry\"\n",
        "    tz_source: str = \"UTC\",\n",
        "    tz_target: str = \"UTC\",\n",
        "    # ==== Salvar m√©tricas no MongoDB ====\n",
        "    save_metrics_to_mongo: bool = False,\n",
        "    mongo_uri: str = \"mongodb://127.0.0.1:27017\",\n",
        "    mongo_db: str = \"telemetria\",\n",
        "    mongo_coll_job: str = \"pipeline_runs\",\n",
        "    mongo_coll_daily: str = \"ev_metrics_daily\",\n",
        "    mongo_ttl_days: int | None = None,\n",
        "):\n",
        "    spark = build_spark()\n",
        "    job_start = datetime.now(timezone.utc).isoformat()\n",
        "\n",
        "    # 1) ingest√£o\n",
        "    raw = read_raw(spark, input_path, input_format)\n",
        "\n",
        "    # 2) padroniza√ß√£o\n",
        "    std = standardize(raw, tz_source=tz_source, tz_target=tz_target)\n",
        "\n",
        "    # 3) tratamento\n",
        "    clean, quarantine = with_quality_flags(std)\n",
        "\n",
        "    # 4) enriquecimento\n",
        "    enriched = enrich(clean)\n",
        "\n",
        "    # quarentena opcional\n",
        "    quarantine_path = output_path.rstrip(\"/\") + \"/_quarantine\"\n",
        "    if quarantine.count() > 0:\n",
        "        (quarantine\n",
        "         .withColumn(\"ano\", F.year(\"event_ts_utc\"))\n",
        "         .withColumn(\"mes\", F.month(\"event_ts_utc\"))\n",
        "         .write.mode(\"append\").partitionBy(\"ano\",\"mes\")\n",
        "         .parquet(quarantine_path))\n",
        "\n",
        "    # 5) m√©tricas do job\n",
        "    metrics = compute_quality_metrics(clean=enriched, quarantine=quarantine)\n",
        "\n",
        "    # 6) grava√ß√£o parquet (schema evolution simples)\n",
        "    df_final = merge_with_existing_if_any(spark, enriched, output_path)\n",
        "    write_parquet(df_final, output_path=output_path,\n",
        "                  mode=(\"overwrite\" if mode==\"overwrite\" else (\"overwrite_partitions\" if mode==\"overwrite_partitions\" else \"append\")),\n",
        "                  partition_cols=[\"ano\",\"mes\"])\n",
        "    df_final.printSchema()\n",
        "\n",
        "    # 7) cat√°logo (opcional)\n",
        "    if register_table:\n",
        "        register_in_catalog(spark, table_name=register_table, location=output_path)\n",
        "\n",
        "    # Metadados em disco\n",
        "    exec_log = {\n",
        "        \"job_name\": \"EV_Telemetry_Batch\",\n",
        "        \"job_start_utc\": job_start,\n",
        "        \"job_end_utc\": datetime.now(timezone.utc).isoformat(),\n",
        "        \"input_path\": input_path,\n",
        "        \"output_path\": output_path,\n",
        "        \"read_format\": input_format or infer_format_from_path(input_path) or \"json\",\n",
        "        \"mode\": mode,\n",
        "        \"records_clean\": metrics.get(\"clean_rows\", 0),\n",
        "        \"records_quarantine\": metrics.get(\"quarantine_rows\", 0),\n",
        "        \"pct_clean\": metrics.get(\"pct_clean\", 0.0),\n",
        "        \"pct_quarantine\": metrics.get(\"pct_quarantine\", 0.0),\n",
        "        \"low_soc_rows\": metrics.get(\"low_soc_rows\", 0),\n",
        "        \"spark_version\": spark.version,\n",
        "    }\n",
        "    dict_schema = schema_to_dict(df_final)\n",
        "    write_metadata_files(spark, output_path, dict_schema, exec_log)\n",
        "\n",
        "    # ==== Gravar m√©tricas no MongoDB ====\n",
        "    if save_metrics_to_mongo:\n",
        "        store = MongoMetricsStore(\n",
        "            uri=mongo_uri, db=mongo_db, coll_job=mongo_coll_job, ttl_days=mongo_ttl_days\n",
        "        )\n",
        "        store.write_job_metrics(exec_log=exec_log, metrics=metrics)\n",
        "\n",
        "        # daily rollup por ve√≠culo/data\n",
        "        daily = compute_daily_vehicle_metrics(enriched)\n",
        "        insert_dataframe_to_mongo(daily, uri=mongo_uri, db=mongo_db, collection=mongo_coll_daily)\n",
        "\n",
        "        store.close()\n",
        "\n",
        "    return {\"metrics\": metrics, \"exec_log\": exec_log, \"schema\": dict_schema}"
      ],
      "metadata": {
        "id": "MqxnG8-av0tz"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criando sess√£o Spark"
      ],
      "metadata": {
        "id": "Keupqpq_AqSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder \\\n",
        "    .appName(\"EV_Telemetry_Batch\") \\\n",
        "    .config(\"spark.sql.parquet.compression.codec\", \"snappy\") \\\n",
        "    .config(\"spark.sql.sources.partitionOverwriteMode\",\"dynamic\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "BYOGH00vu_RF"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rodando o pipeline"
      ],
      "metadata": {
        "id": "exUDnGPVAvra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res = run_job(\n",
        "    input_path=\"/content/simulation_output/telemetria.jsonl\",\n",
        "    input_format=\"json\",\n",
        "    output_path=\"/content/pipeline_output\",\n",
        "    mode=\"append\",\n",
        "    save_metrics_to_mongo=True,\n",
        "    mongo_uri=\"mongodb://127.0.0.1:27017\",\n",
        "    mongo_db=\"telemetria\",\n",
        "    mongo_coll_job=\"pipeline_runs\",\n",
        "    mongo_coll_daily=\"ev_metrics_daily\",\n",
        "    mongo_ttl_days=30,\n",
        ")\n",
        "\n",
        "print(res[\"metrics\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAHOEh2LvXBB",
        "outputId": "46f1ddd3-56f8-485c-8a9a-145a512fb25d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- schema_version: string (nullable = true)\n",
            " |-- vehicle_id: string (nullable = true)\n",
            " |-- event_ts_utc: timestamp (nullable = true)\n",
            " |-- soc_pct: double (nullable = true)\n",
            " |-- pack_voltage_v: double (nullable = true)\n",
            " |-- pack_current_a: double (nullable = true)\n",
            " |-- power_kw: double (nullable = true)\n",
            " |-- battery_temp_c: double (nullable = true)\n",
            " |-- motor_temp_c: double (nullable = true)\n",
            " |-- coolant_temp_c: double (nullable = true)\n",
            " |-- tyre_pressure_kpa: array (nullable = true)\n",
            " |    |-- element: double (containsNull = true)\n",
            " |-- speed_kph: double (nullable = true)\n",
            " |-- odometer_km: double (nullable = true)\n",
            " |-- latitude: double (nullable = true)\n",
            " |-- longitude: double (nullable = true)\n",
            " |-- heading_deg: double (nullable = true)\n",
            " |-- ambient_temp_c: double (nullable = true)\n",
            " |-- is_charging: boolean (nullable = true)\n",
            " |-- charge_power_kw: double (nullable = true)\n",
            " |-- health_score: double (nullable = true)\n",
            " |-- fault_code: string (nullable = true)\n",
            " |-- q_not_null__vehicle_id: boolean (nullable = false)\n",
            " |-- q_not_null__event_ts_utc: boolean (nullable = false)\n",
            " |-- q_range__soc_pct: boolean (nullable = true)\n",
            " |-- q_range__battery_temp_c: boolean (nullable = true)\n",
            " |-- q_range__motor_temp_c: boolean (nullable = true)\n",
            " |-- q_range__coolant_temp_c: boolean (nullable = true)\n",
            " |-- q_range__speed_kph: boolean (nullable = true)\n",
            " |-- q_range__latitude: boolean (nullable = true)\n",
            " |-- q_range__longitude: boolean (nullable = true)\n",
            " |-- q_range__heading_deg: boolean (nullable = true)\n",
            " |-- q_range__health_score: boolean (nullable = true)\n",
            " |-- q_range__pack_voltage_v: boolean (nullable = true)\n",
            " |-- q_range__pack_current_a: boolean (nullable = true)\n",
            " |-- q_range__power_kw: boolean (nullable = true)\n",
            " |-- q_range__charge_power_kw: boolean (nullable = true)\n",
            " |-- q_range__odometer_km: boolean (nullable = true)\n",
            " |-- q_range__ambient_temp_c: boolean (nullable = true)\n",
            " |-- q_is_duplicate: boolean (nullable = false)\n",
            " |-- q_iqr__soc_pct: boolean (nullable = true)\n",
            " |-- q_iqr__power_kw: boolean (nullable = true)\n",
            " |-- q_iqr__battery_temp_c: boolean (nullable = true)\n",
            " |-- q_iqr__motor_temp_c: boolean (nullable = true)\n",
            " |-- q_iqr__speed_kph: boolean (nullable = true)\n",
            " |-- event_date: date (nullable = true)\n",
            " |-- ano: integer (nullable = true)\n",
            " |-- mes: integer (nullable = true)\n",
            " |-- dia: integer (nullable = true)\n",
            " |-- hora: integer (nullable = true)\n",
            " |-- is_low_soc: boolean (nullable = true)\n",
            " |-- battery_temp_band: string (nullable = false)\n",
            " |-- vehicle_ts_key: string (nullable = false)\n",
            "\n",
            "{'total_input_rows': 600, 'clean_rows': 120, 'quarantine_rows': 480, 'pct_clean': 20.0, 'pct_quarantine': 80.0, 'low_soc_rows': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conferindo m√©tricas salvas no MongoDB"
      ],
      "metadata": {
        "id": "QMa_RVZBY3Xh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pymongo import MongoClient\n",
        "cli = MongoClient(\"mongodb://127.0.0.1:27017\")\n",
        "\n",
        "print(\"== pipeline_runs ==\")\n",
        "for d in cli[\"telemetria\"][\"pipeline_runs\"].find({}, {\"_id\":0,\"job_name\":1,\"job_start_utc\":1,\"records_clean\":1,\"low_soc_rows\":1}).sort(\"job_start_utc\",-1).limit(3):\n",
        "    print(d)\n",
        "\n",
        "print(\"\\n== ev_metrics_daily ==\")\n",
        "for d in cli[\"telemetria\"][\"ev_metrics_daily\"].find({}, {\"_id\":0,\"event_date\":1,\"vehicle_id\":1,\"rows\":1,\"soc_min\":1,\"soc_p50\":1,\"soc_max\":1,\"low_soc_cnt\":1}).sort([(\"event_date\",-1)]).limit(5):\n",
        "    print(d)\n",
        "cli.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cw5Ll6ZbY2_H",
        "outputId": "cfa3e54d-48f4-4ff9-962d-9a332b8aeaa5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== pipeline_runs ==\n",
            "{'job_name': 'EV_Telemetry_Batch', 'job_start_utc': '2025-08-24T23:24:20.063960+00:00', 'records_clean': 120, 'low_soc_rows': 0}\n",
            "\n",
            "== ev_metrics_daily ==\n",
            "{'vehicle_id': 'EV-00009', 'event_date': '2025-08-24', 'rows': 60, 'soc_min': 67.29, 'soc_p50': 67.31, 'soc_max': 67.32, 'low_soc_cnt': 0}\n",
            "{'vehicle_id': 'EV-00003', 'event_date': '2025-08-24', 'rows': 43, 'soc_min': 87.53, 'soc_p50': 87.53, 'soc_max': 87.54, 'low_soc_cnt': 0}\n",
            "{'vehicle_id': 'EV-00008', 'event_date': '2025-08-24', 'rows': 17, 'soc_min': 91.29, 'soc_p50': 91.29, 'soc_max': 91.3, 'low_soc_cnt': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Salvando arquivo parquet com dados processados"
      ],
      "metadata": {
        "id": "rFKYIHwFZoeQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = (SparkSession.builder\n",
        "         .appName(\"read-parquet\")\n",
        "         .config(\"spark.sql.parquet.mergeSchema\",\"true\")\n",
        "         .getOrCreate())\n",
        "\n",
        "df = (spark.read\n",
        "      .option(\"recursiveFileLookup\", \"true\")\n",
        "      .option(\"pathGlobFilter\", \"*.parquet\")\n",
        "      .parquet(\"/content/pipeline_output\"))   # raiz com tudo dentro"
      ],
      "metadata": {
        "id": "9KT-T7Yp943d"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualizando resultados"
      ],
      "metadata": {
        "id": "BufpI4Qwab1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYSJKuUESzR-",
        "outputId": "4e321a14-ca17-4b9a-a665-58fa0fe96d10"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- schema_version: string (nullable = true)\n",
            " |-- vehicle_id: string (nullable = true)\n",
            " |-- event_ts_utc: timestamp (nullable = true)\n",
            " |-- soc_pct: double (nullable = true)\n",
            " |-- pack_voltage_v: double (nullable = true)\n",
            " |-- pack_current_a: double (nullable = true)\n",
            " |-- power_kw: double (nullable = true)\n",
            " |-- battery_temp_c: double (nullable = true)\n",
            " |-- motor_temp_c: double (nullable = true)\n",
            " |-- coolant_temp_c: double (nullable = true)\n",
            " |-- tyre_pressure_kpa: array (nullable = true)\n",
            " |    |-- element: double (containsNull = true)\n",
            " |-- speed_kph: double (nullable = true)\n",
            " |-- odometer_km: double (nullable = true)\n",
            " |-- latitude: double (nullable = true)\n",
            " |-- longitude: double (nullable = true)\n",
            " |-- heading_deg: double (nullable = true)\n",
            " |-- ambient_temp_c: double (nullable = true)\n",
            " |-- is_charging: boolean (nullable = true)\n",
            " |-- charge_power_kw: double (nullable = true)\n",
            " |-- health_score: double (nullable = true)\n",
            " |-- fault_code: string (nullable = true)\n",
            " |-- q_not_null__vehicle_id: boolean (nullable = true)\n",
            " |-- q_not_null__event_ts_utc: boolean (nullable = true)\n",
            " |-- q_range__soc_pct: boolean (nullable = true)\n",
            " |-- q_range__battery_temp_c: boolean (nullable = true)\n",
            " |-- q_range__motor_temp_c: boolean (nullable = true)\n",
            " |-- q_range__coolant_temp_c: boolean (nullable = true)\n",
            " |-- q_range__speed_kph: boolean (nullable = true)\n",
            " |-- q_range__latitude: boolean (nullable = true)\n",
            " |-- q_range__longitude: boolean (nullable = true)\n",
            " |-- q_range__heading_deg: boolean (nullable = true)\n",
            " |-- q_range__health_score: boolean (nullable = true)\n",
            " |-- q_range__pack_voltage_v: boolean (nullable = true)\n",
            " |-- q_range__pack_current_a: boolean (nullable = true)\n",
            " |-- q_range__power_kw: boolean (nullable = true)\n",
            " |-- q_range__charge_power_kw: boolean (nullable = true)\n",
            " |-- q_range__odometer_km: boolean (nullable = true)\n",
            " |-- q_range__ambient_temp_c: boolean (nullable = true)\n",
            " |-- q_is_duplicate: boolean (nullable = true)\n",
            " |-- q_iqr__soc_pct: boolean (nullable = true)\n",
            " |-- q_iqr__power_kw: boolean (nullable = true)\n",
            " |-- q_iqr__battery_temp_c: boolean (nullable = true)\n",
            " |-- q_iqr__motor_temp_c: boolean (nullable = true)\n",
            " |-- q_iqr__speed_kph: boolean (nullable = true)\n",
            " |-- event_date: date (nullable = true)\n",
            " |-- dia: integer (nullable = true)\n",
            " |-- hora: integer (nullable = true)\n",
            " |-- is_low_soc: boolean (nullable = true)\n",
            " |-- battery_temp_band: string (nullable = true)\n",
            " |-- vehicle_ts_key: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pymongo import MongoClient\n",
        "\n",
        "URI = \"mongodb://127.0.0.1:27017\"   # ajuste se usou outra porta\n",
        "DB  = \"telemetria\"                  # o que usamos no pipeline\n",
        "\n",
        "cli = MongoClient(URI, serverSelectionTimeoutMS=3000)\n",
        "cli.admin.command(\"ping\")\n",
        "print(\"‚úÖ conectado\")\n",
        "\n",
        "# 1) ver bancos e cole√ß√µes\n",
        "print(\"\\n== Bancos ==\")\n",
        "print(cli.list_database_names())\n",
        "\n",
        "print(\"\\n== Cole√ß√µes em\", DB, \"==\")\n",
        "db = cli[DB]\n",
        "print(db.list_collection_names())\n",
        "\n",
        "# 2) contar e amostrar registros das cole√ß√µes mais prov√°veis\n",
        "for coll_name in [\"pipeline_runs\",\"ev_metrics_daily\",\"ev_alerts\"]:\n",
        "    col = db[coll_name]\n",
        "    try:\n",
        "        total = col.count_documents({})\n",
        "        print(f\"\\n[{coll_name}] total docs:\", total)\n",
        "        # √∫ltimos 3 (tenta ordenar por campos comuns)\n",
        "        cursor = col.find({}, {\"_id\":0}).sort([(\"job_start_utc\",-1), (\"event_date\",-1)]).limit(3)\n",
        "        for d in cursor:\n",
        "            print(d)\n",
        "        # 3) ver √≠ndices (inclui TTL se existir)\n",
        "        print(\"√çndices:\")\n",
        "        for idx in col.list_indexes():\n",
        "            ttl = f\" (TTL={idx.get('expireAfterSeconds')}s)\" if 'expireAfterSeconds' in idx else \"\"\n",
        "            print(\" -\", idx[\"name\"], dict(idx[\"key\"]), ttl)\n",
        "    except Exception as e:\n",
        "        print(f\"[{coll_name}] (pode n√£o existir) -> {e}\")\n",
        "\n",
        "cli.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJH_QEzgaaej",
        "outputId": "478948a5-a268-4006-acac-16fc3f77c976"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ conectado\n",
            "\n",
            "== Bancos ==\n",
            "['admin', 'config', 'local', 'telemetria']\n",
            "\n",
            "== Cole√ß√µes em telemetria ==\n",
            "['ev_alerts', 'pipeline_runs', 'ev_metrics_daily']\n",
            "\n",
            "[pipeline_runs] total docs: 1\n",
            "{'job_end_dt': datetime.datetime(2025, 8, 24, 23, 24, 28, 457000), 'metrics': {'total_input_rows': 600, 'clean_rows': 120, 'quarantine_rows': 480, 'pct_clean': 20.0, 'pct_quarantine': 80.0, 'low_soc_rows': 0}, 'job_name': 'EV_Telemetry_Batch', 'job_start_utc': '2025-08-24T23:24:20.063960+00:00', 'job_end_utc': '2025-08-24T23:24:28.457158+00:00', 'input_path': '/content/simulation_output/telemetria.jsonl', 'output_path': '/content/pipeline_output', 'read_format': 'json', 'mode': 'append', 'records_clean': 120, 'records_quarantine': 480, 'pct_clean': 20.0, 'pct_quarantine': 80.0, 'low_soc_rows': 0, 'spark_version': '3.5.1'}\n",
            "√çndices:\n",
            " - _id_ {'_id': 1} \n",
            " - job_name_1_job_start_utc_-1 {'job_name': 1, 'job_start_utc': -1} \n",
            " - job_end_dt_1 {'job_end_dt': 1}  (TTL=2592000s)\n",
            "\n",
            "[ev_metrics_daily] total docs: 3\n",
            "{'vehicle_id': 'EV-00009', 'event_date': '2025-08-24', 'rows': 60, 'soc_min': 67.29, 'soc_p50': 67.31, 'soc_max': 67.32, 'low_soc_cnt': 0, 'speed_avg': 1.4210000000000003}\n",
            "{'vehicle_id': 'EV-00003', 'event_date': '2025-08-24', 'rows': 43, 'soc_min': 87.53, 'soc_p50': 87.53, 'soc_max': 87.54, 'low_soc_cnt': 0, 'speed_avg': 10.673488372093024}\n",
            "{'vehicle_id': 'EV-00008', 'event_date': '2025-08-24', 'rows': 17, 'soc_min': 91.29, 'soc_p50': 91.29, 'soc_max': 91.3, 'low_soc_cnt': 0, 'speed_avg': 13.1}\n",
            "√çndices:\n",
            " - _id_ {'_id': 1} \n",
            " - vehicle_id_1_event_date_-1 {'vehicle_id': 1, 'event_date': -1} \n",
            "\n",
            "[ev_alerts] total docs: 840\n",
            "{'ts': '2025-08-24T23:02:37.636766+00:00', 'ts_dt': datetime.datetime(2025, 8, 24, 23, 2, 37, 636000), 'vehicle_id': 'EV-00002', 'soc_pct': 35.45, 'power_kw': 2.778, 'latitude': -23.488523, 'longitude': -46.615139, 'fault_code': None, 'payload': {'schema_version': '1.0.0', 'vehicle_id': 'EV-00002', 'timestamp': '2025-08-24T23:02:37.636766+00:00', 'metrics': {'soc_pct': 35.45, 'pack_voltage_v': 331.61, 'pack_current_a': 8.79, 'power_kw': 2.778, 'battery_temp_c': 29.58, 'motor_temp_c': 28.6, 'coolant_temp_c': 22.2, 'tyre_pressure_kpa': [210.1, 227.8, 220.9, 212.6], 'speed_kph': 24.39, 'odometer_km': 37571.856, 'latitude': -23.488523, 'longitude': -46.615139, 'heading_deg': 188.7, 'ambient_temp_c': 19.7, 'is_charging': False, 'charge_power_kw': 0.0, 'health_score': 0.983}, 'events': {'fault_code': None}}}\n",
            "{'ts': '2025-08-24T23:02:37.637901+00:00', 'ts_dt': datetime.datetime(2025, 8, 24, 23, 2, 37, 637000), 'vehicle_id': 'EV-00003', 'soc_pct': 59.52, 'power_kw': 1.126, 'latitude': -23.49942, 'longitude': -46.58732, 'fault_code': None, 'payload': {'schema_version': '1.0.0', 'vehicle_id': 'EV-00003', 'timestamp': '2025-08-24T23:02:37.637901+00:00', 'metrics': {'soc_pct': 59.52, 'pack_voltage_v': 390.57, 'pack_current_a': 3.03, 'power_kw': 1.126, 'battery_temp_c': 26.97, 'motor_temp_c': 22.3, 'coolant_temp_c': 19.94, 'tyre_pressure_kpa': [219.3, 239.4, 237.5, 234.4], 'speed_kph': 14.36, 'odometer_km': 70999.808, 'latitude': -23.49942, 'longitude': -46.58732, 'heading_deg': 320.3, 'ambient_temp_c': 26.9, 'is_charging': False, 'charge_power_kw': 0.0, 'health_score': 0.96}, 'events': {'fault_code': None}}}\n",
            "{'ts': '2025-08-24T23:02:37.639557+00:00', 'ts_dt': datetime.datetime(2025, 8, 24, 23, 2, 37, 639000), 'vehicle_id': 'EV-00013', 'soc_pct': 51.65, 'power_kw': 1.804, 'latitude': -23.871764, 'longitude': -46.129428, 'fault_code': None, 'payload': {'schema_version': '1.0.0', 'vehicle_id': 'EV-00013', 'timestamp': '2025-08-24T23:02:37.639557+00:00', 'metrics': {'soc_pct': 51.65, 'pack_voltage_v': 337.32, 'pack_current_a': 5.62, 'power_kw': 1.804, 'battery_temp_c': 25.24, 'motor_temp_c': 33.55, 'coolant_temp_c': 23.09, 'tyre_pressure_kpa': [219.8, 220.6, 231.4, 233.4], 'speed_kph': 14.45, 'odometer_km': 43764.989, 'latitude': -23.871764, 'longitude': -46.129428, 'heading_deg': 148.1, 'ambient_temp_c': 20.1, 'is_charging': False, 'charge_power_kw': 0.0, 'health_score': 0.935}, 'events': {'fault_code': None}}}\n",
            "√çndices:\n",
            " - _id_ {'_id': 1} \n",
            " - vehicle_id_1_ts_dt_-1 {'vehicle_id': 1, 'ts_dt': -1} \n",
            " - ts_dt_1 {'ts_dt': 1}  (TTL=2592000s)\n"
          ]
        }
      ]
    }
  ]
}